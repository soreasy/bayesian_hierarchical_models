{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e073f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e0afe02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone_id</th>\n",
       "      <th>date</th>\n",
       "      <th>total_demand_new</th>\n",
       "      <th>total_demand_new_lag1</th>\n",
       "      <th>total_demand_new_lag2</th>\n",
       "      <th>total_demand_new_lag3</th>\n",
       "      <th>total_demand_new_lag-1</th>\n",
       "      <th>total_demand_new_lag-2</th>\n",
       "      <th>total_demand_new_lag-3</th>\n",
       "      <th>smoothed_total_demand</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-26</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-26</td>\n",
       "      <td>1656.912757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1678.654277</td>\n",
       "      <td>2193.532475</td>\n",
       "      <td>2110.494687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-26</th>\n",
       "      <td>655</td>\n",
       "      <td>2017-06-26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            zone_id        date  total_demand_new  total_demand_new_lag1  \\\n",
       "date_idx                                                                   \n",
       "2017-06-26        1  2017-06-26       1656.912757                    NaN   \n",
       "2017-06-26      655  2017-06-26          0.000000                    NaN   \n",
       "\n",
       "            total_demand_new_lag2  total_demand_new_lag3  \\\n",
       "date_idx                                                   \n",
       "2017-06-26                    NaN                    NaN   \n",
       "2017-06-26                    NaN                    NaN   \n",
       "\n",
       "            total_demand_new_lag-1  total_demand_new_lag-2  \\\n",
       "date_idx                                                     \n",
       "2017-06-26             1678.654277             2193.532475   \n",
       "2017-06-26                0.000000                0.000000   \n",
       "\n",
       "            total_demand_new_lag-3  smoothed_total_demand  year  \n",
       "date_idx                                                         \n",
       "2017-06-26             2110.494687                    NaN  2017  \n",
       "2017-06-26                0.000000                    NaN  2017  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('weekly_dmd.csv')\n",
    "df['date'] = pd.to_datetime(df.date).apply(lambda x: x.date())\n",
    "df = df.set_index(df.date)\n",
    "df.index.rename('date_idx', inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60084c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_start_idx = date(2020,2,17)\n",
    "\n",
    "df_prep = df.loc[(df.date < covid_start_idx)\n",
    "                | (df.date >= covid_start_idx + timedelta(weeks=52))].sort_values('date')\n",
    "\n",
    "df_prep['y_obs'] = df_prep.total_demand_new\n",
    "# df_prep['y_obs'] = df_prep.smoothed_total_demand\n",
    "df_prep['covid_start_m1'] = df_prep.date.apply(lambda x: 1.0 if x == covid_start_idx - timedelta(weeks=1) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7920c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [] remove first X (3?) weeks for each zone?\n",
    "# [] how to align ish\n",
    "    # should be aligned temporally\n",
    "    # can access the season estimates based on time t then?\n",
    "    # will have to do a theano.scan for each of the zones -- for zones that started after the oldest zone, do they not get initial seasons then? are their initial seasons just the 52 prior \n",
    "\n",
    "# maybe initial level and initial trend can be unique to each zone, but other params come from a shared distribution\n",
    "\n",
    "# so the \"parent\" distribution for initial szns should be ordered/accessed based on time\n",
    "\n",
    "# so s'pose we have\n",
    "# szn_len = 4\n",
    "#  t: 0,1,2,3,4,5,...\n",
    "# z1: 3,4,8,2,5,6,...\n",
    "# z2: _,_,_,1,3,4,...\n",
    "\n",
    "# initial_szns = s1,s2,s3,s4\n",
    "\n",
    "# the first non-zero entry for z2 is the 4th season\n",
    "# so the initial_szns passed to z2's theano.scan should be ordered as [s4,s1,s2,s3]\n",
    "\n",
    "# s1_mu ~ Uniform[0,1]\n",
    "# s1_sigma ~ HalfCauchy(0.5)\n",
    "# s1_mu_z1 ~ TruncatedNormal(s1_mu, s1_sigma, upper=1, lower=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda7d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_list = dd.zone_id.unique()\n",
    "dd['zone_idx'] = dd.zone_id.apply(lambda x: np.where(zone_list == x)[0][0])\n",
    "\n",
    "# does this need to be mapped to [0,len(dd.zone_id.unique())-1] ? seems yes\n",
    "zone_idx = dd.zone_idx.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9044ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d3f08902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_hw_model(zdf, initial_lvl_upper):\n",
    "    szn_len = 52\n",
    "\n",
    "    with pm.Model() as hw_model:\n",
    "    #     initial_level = pm.Normal(f'initial_level', mu=3000, sigma=400)\n",
    "#         initial_level = pm.Uniform(f'initial_level', lower=0, upper=5000)\n",
    "        initial_level = pm.Uniform(f'initial_level', lower=0, upper=initial_lvl_upper, shape=(df_prep.zone_id.nunique()))\n",
    "    \n",
    "        smoothing_level_mu = pm.Uniform('smoothing_level_mu', lower=0, upper=1)\n",
    "        smoothing_level_sigma = pm.HalfCauchy('smoothing_level_sigma', beta=0.5)\n",
    "        smoothing_level = pm.TruncatedNormal('smoothing_level', mu=smoothing_level_mu, sigma=smoothing_level_sigma, lower=0, upper=1, shape=(df_prep.zone_id.nunique()))\n",
    "#         smoothing_level = pm.Normal('smoothing_level', mu=0.5, sigma=0.5)\n",
    "\n",
    "    #     initial_trend = pm.Normal(f'initial_trend', mu=0, sigma=100)\n",
    "#         initial_trend = pm.Uniform(f'initial_trend', lower=-1000, upper=1000)\n",
    "        initial_trend = pm.Uniform(f'initial_trend', lower=-initial_lvl_upper/2, upper=initial_lvl_upper/2)\n",
    "        \n",
    "        smoothing_trend_mu = pm.Uniform('smoothing_trend_mu', lower=0, upper=1)\n",
    "        smoothing_trend_sigma = pm.HalfCauchy('smoothing_trend_sigma', beta=0.5)\n",
    "        smoothing_trend = pm.TruncatedNormal('smoothing_trend', mu=smoothing_trend_mu, sigma=smoothing_trend_sigma, lower=0, upper=1, shape=(df_prep.zone_id.nunique()))\n",
    "#         smoothing_trend = pm.Uniform('smoothing_trend', lower=0, upper=1)\n",
    "    #     smoothing_trend = pm.Normal('smoothing_trend', mu=0.5, sigma=0.5)\n",
    "    \n",
    "        \n",
    "        # \n",
    "        initial_szns_mus = pm.Normal('initial_szns_mus', mu=1.0, sigma=0.2, shape=(szn_len))\n",
    "        initial_szns = pm.Normal('initial_szns', mu=initial_szns_mus, sigma=0.2, shape=(df_prep.zone_id.nunique(), szn_len))\n",
    "    #     initial_szns = pm.Uniform('initial_szns', lower=0.7, upper=1.3, shape=(szn_len))\n",
    "    #     smoothing_season = pm.Uniform('smoothing_season', lower=0, upper=1)\n",
    "    #     smoothing_season = pm.Uniform('smoothing_season', lower=0, upper=1)\n",
    "    #     smoothing_season = pm.Uniform('smoothing_season', lower=0, upper=1-smoothing_level)\n",
    "        smoothing_season_mu = pm.Uniform('smoothing_season_mu', lower=0, upper=1)\n",
    "        smoothing_season_sigma = pm.HalfCauchy('smoothing_season_sigma', beta=0.5)\n",
    "        smoothing_season = pm.TruncatedNormal('smoothing_season', mu=smoothing_season_mu, sigma=smoothing_season_sigma, lower=0, upper=1, shape=(df_prep.zone_id.nunique()))\n",
    "#         smoothing_season = pm.TruncatedNormal('smoothing_season', mu=0.2, sigma=0.5, lower=0, upper=0.8)\n",
    "    #     smoothing_season = pm.Normal('smoothing_season', mu=0.5, sigma=0.5)\n",
    "\n",
    "        ys = tt.as_tensor_variable(zdf['y_obs'])\n",
    "        is_covid_start = tt.as_tensor_variable(zdf['covid_start_m1'])\n",
    "    #     covid_level_change = pm.Normal('covid_level_change', mu=15000, sigma=2000)\n",
    "        covid_level_change = pm.Uniform('covid_level_change', lower=0, upper=5000)\n",
    "#         covid_level_change = pm.Normal('covid_level_change', mu=2000, sigma=1000)\n",
    "    #     covid_level_change2 = pm.Normal('covid_level_change2', mu=20000, sigma=2000)\n",
    "        covid_level_change2 = pm.Uniform('covid_level_change2', lower=0, upper=5000)\n",
    "    #     covid_level_change2 = pm.Normal('covid_level_change2', mu=covid_level_change, sigma=1000)\n",
    "    #     covid_level_change2 = pm.Normal('covid_level_change2', mu=covid_level_change, sigma=1000)\n",
    "\n",
    "        def hw_component_wise(y, covid_start, prior_level, prior_trend, szn_m52):\n",
    "            updated_szn = smoothing_season * y / (prior_level + prior_trend) + (1 - smoothing_season) * szn_m52\n",
    "\n",
    "\n",
    "            next_level = smoothing_level * (y/szn_m52) + (1 - smoothing_level)*(prior_level + prior_trend) + covid_start*covid_level_change\n",
    "            next_trend = smoothing_trend * (next_level - prior_level) + (1 - smoothing_trend)*prior_trend - covid_start*smoothing_trend*covid_level_change2\n",
    "\n",
    "\n",
    "            return next_level, next_trend, updated_szn\n",
    "\n",
    "        # pass initial_level[zone_idx], initial_trend[zone_idx], initial_szns[zone_idx] etc\n",
    "        # should the scan be wrapped in a scan too??\n",
    "            # the outer scan would loop through each zone and pass each zone's initial params and data to the inner scan that calls hw_component_wise\n",
    "        outputs, updates = theano.scan(hw_component_wise,\n",
    "               sequences = [\n",
    "                   ys[1:],\n",
    "#                    ys[szn_len:],\n",
    "                   is_covid_start[1:]\n",
    "#                    is_covid_start[szn_len:]\n",
    "        #            post_covid[szn_len:]\n",
    "               ],\n",
    "               outputs_info = [\n",
    "                   dict(initial = initial_level, taps=None),\n",
    "                   dict(initial = initial_trend, taps=None),\n",
    "                   dict(initial = initial_szns, taps=[-szn_len])\n",
    "               ], \n",
    "        #            non_sequences = \n",
    "               )\n",
    "\n",
    "\n",
    "        levels = outputs[0]\n",
    "        trends = outputs[1]\n",
    "        seasons = outputs[2]\n",
    "\n",
    "\n",
    "        levels_f = pm.math.concatenate([initial_level.reshape(1,1), levels[:-1]])\n",
    "        trends_f = pm.math.concatenate([initial_trend.reshape(1,1), trends[:-1]])\n",
    "        seasons_f = pm.math.concatenate([initial_szns, seasons[:-szn_len]])\n",
    "\n",
    "        levels_and_trends = pm.math.stack([levels_f, trends_f])\n",
    "        level_plus_trend = levels_and_trends.sum(axis=0)\n",
    "\n",
    "        level_plus_trend_and_seasons = pm.math.stack([level_plus_trend, seasons_f])\n",
    "        y_hats = level_plus_trend_and_seasons.prod(axis=0)\n",
    "\n",
    "        sig = pm.HalfCauchy('sigma', beta=10)\n",
    "#         y_like = pm.Normal('y_like', mu=y_hats, sigma=sig, observed=zdf.iloc[szn_len-1:-1, :]['y_obs_lag-1'])\n",
    "        y_like = pm.Normal('y_like', mu=y_hats, sigma=sig, observed=zdf.iloc[:-1, :]['y_obs_lag-1'])\n",
    "        \n",
    "    map_estimate = pm.find_MAP(model=hw_model)\n",
    "    \n",
    "    return map_estimate, ys, is_covid_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b88d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = df_prep.loc[df_prep.zone_id.isin([1,13])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1c50fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-8e0f7511f979>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d2['zone_idx'] = d2.zone_id.apply(lambda x: np.where(zone_list == x)[0][0])\n"
     ]
    }
   ],
   "source": [
    "zone_list = d2.zone_id.unique()\n",
    "d2['zone_idx'] = d2.zone_id.apply(lambda x: np.where(zone_list == x)[0][0])\n",
    "\n",
    "# does this need to be mapped to [0,len(dd.zone_id.unique())-1] ? seems yes\n",
    "zone_idx = d2.zone_idx.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbecd3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone_id</th>\n",
       "      <th>date</th>\n",
       "      <th>total_demand_new</th>\n",
       "      <th>total_demand_new_lag1</th>\n",
       "      <th>total_demand_new_lag2</th>\n",
       "      <th>total_demand_new_lag3</th>\n",
       "      <th>total_demand_new_lag-1</th>\n",
       "      <th>total_demand_new_lag-2</th>\n",
       "      <th>total_demand_new_lag-3</th>\n",
       "      <th>smoothed_total_demand</th>\n",
       "      <th>year</th>\n",
       "      <th>y_obs</th>\n",
       "      <th>covid_start_m1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-26</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-26</td>\n",
       "      <td>1656.912757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1678.654277</td>\n",
       "      <td>2193.532475</td>\n",
       "      <td>2110.494687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>1656.912757</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-26</th>\n",
       "      <td>13</td>\n",
       "      <td>2017-06-26</td>\n",
       "      <td>272.496914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277.941595</td>\n",
       "      <td>354.757040</td>\n",
       "      <td>345.466023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>272.496914</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-03</th>\n",
       "      <td>13</td>\n",
       "      <td>2017-07-03</td>\n",
       "      <td>277.941595</td>\n",
       "      <td>272.496914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>354.757040</td>\n",
       "      <td>345.466023</td>\n",
       "      <td>350.206164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>277.941595</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-03</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-07-03</td>\n",
       "      <td>1678.654277</td>\n",
       "      <td>1656.912757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2193.532475</td>\n",
       "      <td>2110.494687</td>\n",
       "      <td>2194.632691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>1678.654277</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-10</th>\n",
       "      <td>13</td>\n",
       "      <td>2017-07-10</td>\n",
       "      <td>354.757040</td>\n",
       "      <td>277.941595</td>\n",
       "      <td>272.496914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>345.466023</td>\n",
       "      <td>350.206164</td>\n",
       "      <td>360.568384</td>\n",
       "      <td>311.527674</td>\n",
       "      <td>2017</td>\n",
       "      <td>354.757040</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            zone_id        date  total_demand_new  total_demand_new_lag1  \\\n",
       "date_idx                                                                   \n",
       "2017-06-26        1  2017-06-26       1656.912757                    NaN   \n",
       "2017-06-26       13  2017-06-26        272.496914                    NaN   \n",
       "2017-07-03       13  2017-07-03        277.941595             272.496914   \n",
       "2017-07-03        1  2017-07-03       1678.654277            1656.912757   \n",
       "2017-07-10       13  2017-07-10        354.757040             277.941595   \n",
       "\n",
       "            total_demand_new_lag2  total_demand_new_lag3  \\\n",
       "date_idx                                                   \n",
       "2017-06-26                    NaN                    NaN   \n",
       "2017-06-26                    NaN                    NaN   \n",
       "2017-07-03                    NaN                    NaN   \n",
       "2017-07-03                    NaN                    NaN   \n",
       "2017-07-10             272.496914                    NaN   \n",
       "\n",
       "            total_demand_new_lag-1  total_demand_new_lag-2  \\\n",
       "date_idx                                                     \n",
       "2017-06-26             1678.654277             2193.532475   \n",
       "2017-06-26              277.941595              354.757040   \n",
       "2017-07-03              354.757040              345.466023   \n",
       "2017-07-03             2193.532475             2110.494687   \n",
       "2017-07-10              345.466023              350.206164   \n",
       "\n",
       "            total_demand_new_lag-3  smoothed_total_demand  year        y_obs  \\\n",
       "date_idx                                                                       \n",
       "2017-06-26             2110.494687                    NaN  2017  1656.912757   \n",
       "2017-06-26              345.466023                    NaN  2017   272.496914   \n",
       "2017-07-03              350.206164                    NaN  2017   277.941595   \n",
       "2017-07-03             2194.632691                    NaN  2017  1678.654277   \n",
       "2017-07-10              360.568384             311.527674  2017   354.757040   \n",
       "\n",
       "            covid_start_m1  \n",
       "date_idx                    \n",
       "2017-06-26             0.0  \n",
       "2017-06-26             0.0  \n",
       "2017-07-03             0.0  \n",
       "2017-07-03             0.0  \n",
       "2017-07-10             0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9044e27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test that we can do the hierarchical scanning business\n",
    "szn_len = 4\n",
    "d = pd.DataFrame({'zone_id': [1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2],\n",
    "#                   'y_obs': [1,2,3,4,2,3,4,5,3,1,2,3,4,1],\n",
    "                  'y_obs': [1,2,3,4,2,3,4,5,3,0,0,0,0,1,2,3,4,1],\n",
    "                  't': [1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "10269404",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_list = d.zone_id.unique()\n",
    "d['zone_idx'] = d.zone_id.apply(lambda x: np.where(zone_list == x)[0][0])\n",
    "d['covid_start_m1'] = d.t.apply(lambda x: 1 if x == 7 else 0)\n",
    "\n",
    "# does this need to be mapped to [0,len(dd.zone_id.unique())-1] ? seems yes\n",
    "zone_idx = d.zone_idx.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f60b58e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone_id</th>\n",
       "      <th>y_obs</th>\n",
       "      <th>t</th>\n",
       "      <th>zone_idx</th>\n",
       "      <th>covid_start_m1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    zone_id  y_obs  t  zone_idx  covid_start_m1\n",
       "0         1      1  1         0               0\n",
       "1         1      2  2         0               0\n",
       "2         1      3  3         0               0\n",
       "3         1      4  4         0               0\n",
       "4         1      2  5         0               0\n",
       "5         1      3  6         0               0\n",
       "6         1      4  7         0               1\n",
       "7         1      5  8         0               0\n",
       "8         1      3  9         0               0\n",
       "9         2      0  1         1               0\n",
       "10        2      0  2         1               0\n",
       "11        2      0  3         1               0\n",
       "12        2      0  4         1               0\n",
       "13        2      1  5         1               0\n",
       "14        2      2  6         1               0\n",
       "15        2      3  7         1               1\n",
       "16        2      4  8         1               0\n",
       "17        2      1  9         1               0"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b2136b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(zone_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995879e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the \"parent\" distribution for initial szns should be ordered/accessed based on time\n",
    "\n",
    "# so s'pose we have\n",
    "# szn_len = 4\n",
    "#  t: 0,1,2,3,4,5,...\n",
    "# z1: 3,4,8,2,5,6,...\n",
    "# z2: _,_,_,1,3,4,...\n",
    "\n",
    "# initial_szns = s1,s2,s3,s4\n",
    "\n",
    "# the first non-zero entry for z2 is the 4th season\n",
    "# so the initial_szns passed to z2's theano.scan should be ordered as [s4,s1,s2,s3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df76d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w/ what ive been doing, we havent worried about which szn corresponds to which t, we just start from wherever there is demand (or 3rd week w/ demand)\n",
    "# now though, we should always index on a particular t/week #\n",
    "# ie make initial_szns[:, 0] correspond to first week in year, initial_szns[:, 51] corresponding to last, etc\n",
    "# so given the first_t, we want:\n",
    "\n",
    "initial_szns[z_idx, first_t%52:szn_len] + initial_szns[z_idx, :first_t%52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7adc2172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4][2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9c4266b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54200846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0,...,51]\n",
    "# []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "410ac77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "52%52, 53%52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "90c86429",
   "metadata": {},
   "outputs": [],
   "source": [
    "theano.config.compute_test_value = 'raise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "699f81f4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# def test(x, prev_output):\n",
    "def test(x):\n",
    "    return pm.math.floatX(x**2)\n",
    "\n",
    "outputs, updates = theano.scan(test,\n",
    "                               sequences=[\n",
    "                                   np.array([1.0,2.0,3.0,4.0])\n",
    "#                                    tt.as_tensor_variable([1.0,2.0,3.0,4.0])\n",
    "                               ],\n",
    "#                               outputs_info=[\n",
    "#                                   dict(initial=pm.math.floatX(0), taps=None)\n",
    "#                               ]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9c21022d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "for{cpu,scan_fn}.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9a1459ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  4.,  9., 16.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.get_test_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "f059081f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "szn_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "e6fdb884",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as test_hw_model:\n",
    "#     initial_level = pm.Normal(f'initial_level', mu=3000, sigma=400)\n",
    "#         initial_level = pm.Uniform(f'initial_level', lower=0, upper=5000)\n",
    "    initial_lvl_upper = 10000\n",
    "    initial_level = pm.Uniform(f'initial_level', lower=0, upper=initial_lvl_upper, shape=(d.zone_id.nunique()))\n",
    "\n",
    "    smoothing_level_mu = pm.Uniform('smoothing_level_mu', lower=0, upper=1)\n",
    "    smoothing_level_sigma = pm.HalfCauchy('smoothing_level_sigma', beta=0.5)\n",
    "    smoothing_level = pm.TruncatedNormal('smoothing_level', mu=smoothing_level_mu, sigma=smoothing_level_sigma, lower=0, upper=1, shape=(d.zone_id.nunique()))\n",
    "#         smoothing_level = pm.Normal('smoothing_level', mu=0.5, sigma=0.5)\n",
    "\n",
    "#     initial_trend = pm.Normal(f'initial_trend', mu=0, sigma=100)\n",
    "#         initial_trend = pm.Uniform(f'initial_trend', lower=-1000, upper=1000)\n",
    "    initial_trend = pm.Uniform(f'initial_trend', lower=-initial_lvl_upper/2, upper=initial_lvl_upper/2, shape=(d.zone_id.nunique()))\n",
    "\n",
    "    smoothing_trend_mu = pm.Uniform('smoothing_trend_mu', lower=0, upper=1)\n",
    "    smoothing_trend_sigma = pm.HalfCauchy('smoothing_trend_sigma', beta=0.5)\n",
    "    smoothing_trend = pm.TruncatedNormal('smoothing_trend', mu=smoothing_trend_mu, sigma=smoothing_trend_sigma, lower=0, upper=1, shape=(d.zone_id.nunique()))\n",
    "#         smoothing_trend = pm.Uniform('smoothing_trend', lower=0, upper=1)\n",
    "#     smoothing_trend = pm.Normal('smoothing_trend', mu=0.5, sigma=0.5)\n",
    "\n",
    "\n",
    "    # \n",
    "    initial_szns_mus = pm.Normal('initial_szns_mus', mu=1.0, sigma=0.2, shape=(szn_len))\n",
    "    initial_szns = pm.Normal('initial_szns', mu=initial_szns_mus, sigma=0.2, shape=(d.zone_id.nunique(), szn_len))\n",
    "#     initial_szns = pm.Uniform('initial_szns', lower=0.7, upper=1.3, shape=(szn_len))\n",
    "#     smoothing_season = pm.Uniform('smoothing_season', lower=0, upper=1)\n",
    "#     smoothing_season = pm.Uniform('smoothing_season', lower=0, upper=1)\n",
    "#     smoothing_season = pm.Uniform('smoothing_season', lower=0, upper=1-smoothing_level)\n",
    "    smoothing_season_mu = pm.Uniform('smoothing_season_mu', lower=0, upper=1)\n",
    "    smoothing_season_sigma = pm.HalfCauchy('smoothing_season_sigma', beta=0.5)\n",
    "    smoothing_season = pm.TruncatedNormal('smoothing_season', mu=smoothing_season_mu, sigma=smoothing_season_sigma, lower=0, upper=1, shape=(d.zone_id.nunique()))\n",
    "#         smoothing_season = pm.TruncatedNormal('smoothing_season', mu=0.2, sigma=0.5, lower=0, upper=0.8)\n",
    "#     smoothing_season = pm.Normal('smoothing_season', mu=0.5, sigma=0.5)\n",
    "\n",
    "#     ys = tt.as_tensor_variable(zdf['y_obs'])\n",
    "#     is_covid_start = tt.as_tensor_variable(zdf['covid_start_m1'])\n",
    "\n",
    "#     covid_level_change = pm.Normal('covid_level_change', mu=15000, sigma=2000)\n",
    "    covid_level_change = pm.Uniform('covid_level_change', lower=0, upper=5000, shape=(d.zone_id.nunique()))\n",
    "#         covid_level_change = pm.Normal('covid_level_change', mu=2000, sigma=1000)\n",
    "#     covid_level_change2 = pm.Normal('covid_level_change2', mu=20000, sigma=2000)\n",
    "    covid_level_change2 = pm.Uniform('covid_level_change2', lower=0, upper=5000, shape=(d.zone_id.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "9a77d5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_szns.get_test_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e4c8ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prep data\n",
    "ys_list, is_covid_start_list, first_t_list =  [], [], []\n",
    "\n",
    "for z_idx in np.unique(zone_idx):\n",
    "    zdf = d.loc[d.zone_idx == z_idx]\n",
    "    \n",
    "    ys_list.append(zdf['y_obs'].tolist())\n",
    "    is_covid_start_list.append(zdf['covid_start_m1'].tolist())\n",
    "    first_t_list.append(zdf.t.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c19a6cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 2, 3, 4, 5, 3], [0, 0, 0, 0, 1, 2, 3, 4, 1]]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "bcc89d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0]]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_covid_start_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "9a833938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_t_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "575243d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5000., 5000.])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_level.get_test_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3586b65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_level.get_test_value().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "da489e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5000., 5000., 5000., 5000., 5000., 5000., 5000., 5000., 5000.,\n",
       "       5000., 5000., 5000., 5000., 5000.])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_level.get_test_value()[zone_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c75f4592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5000., 5000., 5000., 5000., 5000., 5000., 5000., 5000., 5000.,\n",
       "       5000., 5000., 5000., 5000., 5000.])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_level[zone_idx].get_test_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "484df0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 2, 3, 4, 5, 3], [1, 2, 3, 4, 1]]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "591c1834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorConstant{[1 2 3]}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.as_tensor_variable(np.array([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1a5c7b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(zone_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c7b0628c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorConstant{[[1 2 3 4 .. 2 3 4 1]]}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.as_tensor_variable([[1, 2, 3, 4, 2, 3, 4, 5, 3], [0,0,0,0,1, 2, 3, 4, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fcddd362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 2, 3, 4, 1])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.as_tensor_variable([[1, 2, 3, 4, 2, 3, 4, 5, 3], [0,0,0,0,1, 2, 3, 4, 1]])[1].get_test_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1a152cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorConstant{[[1 2]\n",
       " [3 4]]}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.as_tensor_variable([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "24f913b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorConstant{[1 2 3 4 2 3 4 5 3]}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.as_tensor_variable(ys_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "25acd326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 2, 3, 4, 5, 3],\n",
       "       [0, 0, 0, 0, 1, 2, 3, 4, 1]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ys_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "a38a6d96",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# def test(x, prev_output):\n",
    "def test(x,y,o1,o2,o3):\n",
    "#     return pm.math.floatX(x**2), pm.math.floatX(3.0)\n",
    "    return pm.math.floatX(x**2), pm.math.floatX(x**2), pm.math.floatX(x**2)\n",
    "\n",
    "# outputs, updates = theano.scan(test,\n",
    "#                                sequences=[\n",
    "#                                    np.array([1.0,2.0,3.0,4.0])\n",
    "# #                                    tt.as_tensor_variable([1.0,2.0,3.0,4.0])\n",
    "#                                ],\n",
    "# #                               outputs_info=[\n",
    "# #                                   dict(initial=pm.math.floatX(0), taps=None)\n",
    "# #                               ]\n",
    "#                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "d3690c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothing_level.get_test_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "252e8d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hw_component_wise_wrapper(z_idx):\n",
    "    def hw_component_wise(y, covid_start, prior_level, prior_trend, szn_m52):\n",
    "        updated_szn = smoothing_season[z_idx] * y / (prior_level + prior_trend) + (1 - smoothing_season[z_idx]) * szn_m52\n",
    "\n",
    "\n",
    "        next_level = smoothing_level[z_idx] * (y/szn_m52) + (1 - smoothing_level[z_idx])*(prior_level + prior_trend) + covid_start*covid_level_change[z_idx]\n",
    "        next_trend = smoothing_trend[z_idx] * (next_level - prior_level) + (1 - smoothing_trend[z_idx])*prior_trend - covid_start*smoothing_trend[z_idx]*covid_level_change2[z_idx]\n",
    "\n",
    "\n",
    "        return next_level, next_trend, updated_szn\n",
    "    return hw_component_wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "739bda3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2500.)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_level_change[0].get_test_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "a1376113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.5)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothing_season[0].get_test_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "2b5de419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6666666666666667"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothing_level[0].get_test_value()*(1/3) + (1-smoothing_level[0].get_test_value())*(1+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "a83a012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = hw_component_wise_wrapper(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "d3a70b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Elemwise{add,no_inplace}.0,\n",
       " Elemwise{sub,no_inplace}.0,\n",
       " Elemwise{add,no_inplace}.0)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=fn(1,0,1,2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "4a395036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.66666667, 1.66666667, 1.66666667, 1.66666667])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].get_test_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "e2e08abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.33333333, 1.33333333, 1.33333333, 1.33333333])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].get_test_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "733a0b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.66666667)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2].get_test_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ce0622e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_szns[1].get_test_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "10eba73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.scan.basic): Output None (index 0) has a initial state but taps is explicitly set to None \n",
      "WARNING (theano.scan.basic): Output None (index 1) has a initial state but taps is explicitly set to None \n"
     ]
    }
   ],
   "source": [
    "# def inner_scan_for_zone(zone_idx, ys, is_covid_start, first_t):\n",
    "def inner_scan_for_zone(z_idx, ys, is_covid_start):\n",
    "#     zdf = d.loc[d.zone_idx == zone_idx]\n",
    "#     ys = tt.as_tensor_variable(zdf['y_obs'])\n",
    "#     is_covid_start = tt.as_tensor_variable(zdf['covid_start_m1'])\n",
    "#     first_t = zdf.t.min()\n",
    "#     initial_seasons = initial_szns[zone_idx, first_t%szn_len:szn_len] + initial_szns[zone_idx, :first_t%szn_len]\n",
    "\n",
    "#     initial_seasons = pm.math.concatenate([initial_szns[zone_idx, first_t%szn_len:szn_len], initial_szns[zone_idx, :first_t%szn_len]])\n",
    "#     import pdb; pdb.set_trace()\n",
    "\n",
    "#     outputs, updates = theano.scan(test,\n",
    "#                                     sequences=[\n",
    "#                                         ys[1:],\n",
    "#                                         is_covid_start[1:]\n",
    "#                                     ],\n",
    "#                                    outputs_info=[\n",
    "#                                        dict(initial = initial_level[z_idx], taps=None),\n",
    "#                                        dict(initial = initial_trend[z_idx], taps=None),\n",
    "#                                        dict(initial = initial_szns[z_idx], taps=[-szn_len])\n",
    "#                                    ])\n",
    "    \n",
    "#     outputs, updates = theano.scan(hw_component_wise,\n",
    "    outputs, updates = theano.scan(hw_component_wise_wrapper(z_idx),\n",
    "                                  sequences=[\n",
    "                                      ys[1:], # this [1:] is done assuming we padded and shifted y_obs\n",
    "                                      is_covid_start[1:]\n",
    "                                  ],\n",
    "                                  outputs_info=[\n",
    "                                      dict(initial = initial_level[z_idx], taps=None),\n",
    "                                      dict(initial = initial_trend[z_idx], taps=None),\n",
    "                                      dict(initial = initial_szns[z_idx], taps=[-szn_len])\n",
    "#                                       dict(initial = initial_seasons, taps=[-szn_len])\n",
    "                                  ])\n",
    "    return outputs\n",
    "\n",
    "outputs, updates = theano.scan(inner_scan_for_zone,\n",
    "           sequences=[\n",
    "               tt.as_tensor_variable(np.unique(zone_idx)),\n",
    "#                np.unique(zone_idx),\n",
    "               tt.as_tensor_variable(ys_list),\n",
    "#                np.array(ys_list),\n",
    "               tt.as_tensor_variable(is_covid_start_list),\n",
    "#                np.array(is_covid_start_list),\n",
    "#                np.array(first_t_list)\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d041f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the padding for ys[1:], etc\n",
    "# confirm ok that we're padding newer zones with 0's (initial level will be 0 i guess, but should be fine -- since the optimal smoothing_level will still be determined by the non-0 data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "eb1e9824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[for{cpu,scan_fn}.0, for{cpu,scan_fn}.1, for{cpu,scan_fn}.2]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "69022dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2501.        ,  627.25      , -465.1875    , -895.109375  ,\n",
       "        -883.79416827, 1845.30301136,  876.55212782,  173.53125729],\n",
       "       [2500.        ,  625.        , -468.75      , -897.9375    ,\n",
       "        -886.296875  , 1843.09765625,  874.52050781,  170.60236347]])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].get_test_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "ecbe89e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.,  9., 16.,  4.,  9., 16., 25.,  9.],\n",
       "       [ 0.,  0.,  0.,  1.,  4.,  9., 16.,  1.]])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[2].get_test_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "64b07974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.as_tensor_variable(np.unique(zone_idx)).get_test_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "c0c7d2fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "new_order[0] is 1, but the input only has 1 axes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-269-7748ba331718>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzone_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_test_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/site-packages/theano/tensor/var.py\u001b[0m in \u001b[0;36mdimshuffle\u001b[0;34m(self, *pattern)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDimShuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcastable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/site-packages/theano/tensor/elemwise.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_broadcastable, new_order, inplace)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     )\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_broadcastable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    181\u001b[0m                         \u001b[0;34mf\"new_order[{i}] is {j}, but the input only has \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                         \u001b[0;34mf\"{len(input_broadcastable)} axes.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: new_order[0] is 1, but the input only has 1 axes."
     ]
    }
   ],
   "source": [
    "tt.as_tensor_variable(np.unique(zone_idx)).dimshuffle(1,'x').get_test_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "4a3686c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tt.as_tensor_variable(np.unique(zone_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "cd088bf5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TensorConstant' object has no attribute 'padleft'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-270-48687faad271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadleft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'TensorConstant' object has no attribute 'padleft'"
     ]
    }
   ],
   "source": [
    "x.padleft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "e1ab6cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.,  9., 16.,  4.,  9., 16., 25.,  9.],\n",
       "       [ 0.,  0.,  0.,  1.,  4.,  9., 16.,  1.]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].get_test_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "da70f928",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-111-1840a6545aa7>, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-111-1840a6545aa7>\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    return outputs\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "for z_idx in np.unique(zone_idx):\n",
    "    zdf = d2.loc[d2.zone_idx == zone_idx]\n",
    "    ys = tt.as_tensor_variable(zdf['y_obs'])\n",
    "    is_covid_start = tt.as_tensor_variable(zdf['covid_start_m1'])\n",
    "    first_t = zdf.t.min()\n",
    "    initial_seasons = initial_szns[zone_idx, first_t%szn_len:szn_len] + initial_szns[zone_idx, :first_t%szn_len]\n",
    "    \n",
    "    outputs, updates = theano.scan(hw_component_wise,\n",
    "               sequences = [\n",
    "                   ys[1:],\n",
    "#                    ys[szn_len:],\n",
    "                   is_covid_start[1:]\n",
    "#                    is_covid_start[szn_len:]\n",
    "        #            post_covid[szn_len:]\n",
    "               ],\n",
    "               outputs_info = [\n",
    "                   dict(initial = initial_level[zone_idx], taps=None),\n",
    "                   dict(initial = initial_trend[zone_idx], taps=None),\n",
    "                   dict(initial = initial_seasons, taps=[-szn_len])\n",
    "#                    dict(initial = initial_szns[z_idx], taps=[-szn_len])\n",
    "               ], \n",
    "        #            non_sequences = \n",
    "               )\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcc54e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_hw_model(zdf, initial_lvl_upper):\n",
    "    szn_len = 52\n",
    "\n",
    "    with pm.Model() as hw_model:\n",
    "    #     initial_level = pm.Normal(f'initial_level', mu=3000, sigma=400)\n",
    "#         initial_level = pm.Uniform(f'initial_level', lower=0, upper=5000)\n",
    "        initial_level = pm.Uniform(f'initial_level', lower=0, upper=initial_lvl_upper, shape=(df_prep.zone_id.nunique()))\n",
    "    \n",
    "        smoothing_level_mu = pm.Uniform('smoothing_level_mu', lower=0, upper=1)\n",
    "        smoothing_level_sigma = pm.HalfCauchy('smoothing_level_sigma', beta=0.5)\n",
    "        smoothing_level = pm.TruncatedNormal('smoothing_level', mu=smoothing_level_mu, sigma=smoothing_level_sigma, lower=0, upper=1, shape=(df_prep.zone_id.nunique()))\n",
    "#         smoothing_level = pm.Normal('smoothing_level', mu=0.5, sigma=0.5)\n",
    "\n",
    "    #     initial_trend = pm.Normal(f'initial_trend', mu=0, sigma=100)\n",
    "#         initial_trend = pm.Uniform(f'initial_trend', lower=-1000, upper=1000)\n",
    "        initial_trend = pm.Uniform(f'initial_trend', lower=-initial_lvl_upper/2, upper=initial_lvl_upper/2)\n",
    "        \n",
    "        smoothing_trend_mu = pm.Uniform('smoothing_trend_mu', lower=0, upper=1)\n",
    "        smoothing_trend_sigma = pm.HalfCauchy('smoothing_trend_sigma', beta=0.5)\n",
    "        smoothing_trend = pm.TruncatedNormal('smoothing_trend', mu=smoothing_trend_mu, sigma=smoothing_trend_sigma, lower=0, upper=1, shape=(df_prep.zone_id.nunique()))\n",
    "#         smoothing_trend = pm.Uniform('smoothing_trend', lower=0, upper=1)\n",
    "    #     smoothing_trend = pm.Normal('smoothing_trend', mu=0.5, sigma=0.5)\n",
    "    \n",
    "        \n",
    "        # \n",
    "        initial_szns_mus = pm.Normal('initial_szns_mus', mu=1.0, sigma=0.2, shape=(szn_len))\n",
    "        initial_szns = pm.Normal('initial_szns', mu=initial_szns_mus, sigma=0.2, shape=(df_prep.zone_id.nunique(), szn_len))\n",
    "    #     initial_szns = pm.Uniform('initial_szns', lower=0.7, upper=1.3, shape=(szn_len))\n",
    "    #     smoothing_season = pm.Uniform('smoothing_season', lower=0, upper=1)\n",
    "    #     smoothing_season = pm.Uniform('smoothing_season', lower=0, upper=1)\n",
    "    #     smoothing_season = pm.Uniform('smoothing_season', lower=0, upper=1-smoothing_level)\n",
    "        smoothing_season_mu = pm.Uniform('smoothing_season_mu', lower=0, upper=1)\n",
    "        smoothing_season_sigma = pm.HalfCauchy('smoothing_season_sigma', beta=0.5)\n",
    "        smoothing_season = pm.TruncatedNormal('smoothing_season', mu=smoothing_season_mu, sigma=smoothing_season_sigma, lower=0, upper=1, shape=(df_prep.zone_id.nunique()))\n",
    "#         smoothing_season = pm.TruncatedNormal('smoothing_season', mu=0.2, sigma=0.5, lower=0, upper=0.8)\n",
    "    #     smoothing_season = pm.Normal('smoothing_season', mu=0.5, sigma=0.5)\n",
    "\n",
    "        ys = tt.as_tensor_variable(zdf['y_obs'])\n",
    "        is_covid_start = tt.as_tensor_variable(zdf['covid_start_m1'])\n",
    "    #     covid_level_change = pm.Normal('covid_level_change', mu=15000, sigma=2000)\n",
    "        covid_level_change = pm.Uniform('covid_level_change', lower=0, upper=5000)\n",
    "#         covid_level_change = pm.Normal('covid_level_change', mu=2000, sigma=1000)\n",
    "    #     covid_level_change2 = pm.Normal('covid_level_change2', mu=20000, sigma=2000)\n",
    "        covid_level_change2 = pm.Uniform('covid_level_change2', lower=0, upper=5000)\n",
    "    #     covid_level_change2 = pm.Normal('covid_level_change2', mu=covid_level_change, sigma=1000)\n",
    "    #     covid_level_change2 = pm.Normal('covid_level_change2', mu=covid_level_change, sigma=1000)\n",
    "\n",
    "        def hw_component_wise(y, covid_start, prior_level, prior_trend, szn_m52):\n",
    "            updated_szn = smoothing_season * y / (prior_level + prior_trend) + (1 - smoothing_season) * szn_m52\n",
    "\n",
    "\n",
    "            next_level = smoothing_level * (y/szn_m52) + (1 - smoothing_level)*(prior_level + prior_trend) + covid_start*covid_level_change\n",
    "            next_trend = smoothing_trend * (next_level - prior_level) + (1 - smoothing_trend)*prior_trend - covid_start*smoothing_trend*covid_level_change2\n",
    "\n",
    "\n",
    "            return next_level, next_trend, updated_szn\n",
    "\n",
    "        # pass initial_level[zone_idx], initial_trend[zone_idx], initial_szns[zone_idx] etc\n",
    "        # should the scan be wrapped in a scan too??\n",
    "            # the outer scan would loop through each zone and pass each zone's initial params and data to the inner scan that calls hw_component_wise\n",
    "        outputs, updates = theano.scan(hw_component_wise,\n",
    "               sequences = [\n",
    "                   ys[1:],\n",
    "#                    ys[szn_len:],\n",
    "                   is_covid_start[1:]\n",
    "#                    is_covid_start[szn_len:]\n",
    "        #            post_covid[szn_len:]\n",
    "               ],\n",
    "               outputs_info = [\n",
    "                   dict(initial = initial_level, taps=None),\n",
    "                   dict(initial = initial_trend, taps=None),\n",
    "                   dict(initial = initial_szns, taps=[-szn_len])\n",
    "               ], \n",
    "        #            non_sequences = \n",
    "               )\n",
    "\n",
    "\n",
    "        levels = outputs[0]\n",
    "        trends = outputs[1]\n",
    "        seasons = outputs[2]\n",
    "\n",
    "\n",
    "        levels_f = pm.math.concatenate([initial_level.reshape(1,1), levels[:-1]])\n",
    "        trends_f = pm.math.concatenate([initial_trend.reshape(1,1), trends[:-1]])\n",
    "        seasons_f = pm.math.concatenate([initial_szns, seasons[:-szn_len]])\n",
    "\n",
    "        levels_and_trends = pm.math.stack([levels_f, trends_f])\n",
    "        level_plus_trend = levels_and_trends.sum(axis=0)\n",
    "\n",
    "        level_plus_trend_and_seasons = pm.math.stack([level_plus_trend, seasons_f])\n",
    "        y_hats = level_plus_trend_and_seasons.prod(axis=0)\n",
    "\n",
    "        sig = pm.HalfCauchy('sigma', beta=10)\n",
    "#         y_like = pm.Normal('y_like', mu=y_hats, sigma=sig, observed=zdf.iloc[szn_len-1:-1, :]['y_obs_lag-1'])\n",
    "        y_like = pm.Normal('y_like', mu=y_hats, sigma=sig, observed=zdf.iloc[:-1, :]['y_obs_lag-1'])\n",
    "        \n",
    "    map_estimate = pm.find_MAP(model=hw_model)\n",
    "    \n",
    "    return map_estimate, ys, is_covid_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14c793e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719b9c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b9f801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9062f080",
   "metadata": {},
   "outputs": [],
   "source": [
    "### dampened\n",
    "\n",
    "# when training, should we train on the horizon of interest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ff157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_hw_model(zdf, initial_lvl_upper):\n",
    "    szn_len = 52\n",
    "\n",
    "    with pm.Model() as hw_model:\n",
    "    #     initial_level = pm.Normal(f'initial_level', mu=3000, sigma=400)\n",
    "#         initial_level = pm.Uniform(f'initial_level', lower=0, upper=5000)\n",
    "        initial_level = pm.Uniform(f'initial_level', lower=0, upper=initial_lvl_upper)\n",
    "        smoothing_level = pm.Uniform('smoothing_level', lower=0, upper=1)\n",
    "#         smoothing_level = pm.Normal('smoothing_level', mu=0.5, sigma=0.5)\n",
    "\n",
    "    #     initial_trend = pm.Normal(f'initial_trend', mu=0, sigma=100)\n",
    "#         initial_trend = pm.Uniform(f'initial_trend', lower=-1000, upper=1000)\n",
    "        initial_trend = pm.Uniform(f'initial_trend', lower=-initial_lvl_upper/2, upper=initial_lvl_upper/2)\n",
    "        smoothing_trend = pm.Uniform('smoothing_trend', lower=0, upper=1)\n",
    "    #     smoothing_trend = pm.Normal('smoothing_trend', mu=0.5, sigma=0.5)\n",
    "\n",
    "        initial_szns = pm.Normal('initial_szns', mu=1.0, sigma=0.2, shape=(szn_len))\n",
    "    #     initial_szns = pm.Uniform('initial_szns', lower=0.7, upper=1.3, shape=(szn_len))\n",
    "    #     smoothing_season = pm.Uniform('smoothing_season', lower=0, upper=1)\n",
    "    #     smoothing_season = pm.Uniform('smoothing_season', lower=0, upper=1)\n",
    "    #     smoothing_season = pm.Uniform('smoothing_season', lower=0, upper=1-smoothing_level)\n",
    "        smoothing_season = pm.TruncatedNormal('smoothing_season', mu=0.2, sigma=0.5, lower=0, upper=0.8)\n",
    "    #     smoothing_season = pm.Normal('smoothing_season', mu=0.5, sigma=0.5)\n",
    "    \n",
    "        dampener = pm.Uniform('dampener', lower=0, upper=1)\n",
    "\n",
    "        ys = tt.as_tensor_variable(zdf['y_obs'])\n",
    "        is_covid_start = tt.as_tensor_variable(zdf['covid_start_m1'])\n",
    "    #     covid_level_change = pm.Normal('covid_level_change', mu=15000, sigma=2000)\n",
    "        covid_level_change = pm.Uniform('covid_level_change', lower=0, upper=5000)\n",
    "#         covid_level_change = pm.Normal('covid_level_change', mu=2000, sigma=1000)\n",
    "    #     covid_level_change2 = pm.Normal('covid_level_change2', mu=20000, sigma=2000)\n",
    "        covid_level_change2 = pm.Uniform('covid_level_change2', lower=0, upper=5000)\n",
    "    #     covid_level_change2 = pm.Normal('covid_level_change2', mu=covid_level_change, sigma=1000)\n",
    "    #     covid_level_change2 = pm.Normal('covid_level_change2', mu=covid_level_change, sigma=1000)\n",
    "\n",
    "        def hw_component_wise(y, covid_start, prior_level, prior_trend, szn_m52):\n",
    "            updated_szn = smoothing_season * y / (prior_level + dampener*prior_trend) + (1 - smoothing_season) * szn_m52\n",
    "\n",
    "\n",
    "            next_level = smoothing_level * (y/szn_m52) + (1 - smoothing_level)*(prior_level + dampener*prior_trend) + covid_start*covid_level_change\n",
    "            next_trend = smoothing_trend * (next_level - prior_level) + (1 - smoothing_trend)*dampener*prior_trend - covid_start*smoothing_trend*covid_level_change2\n",
    "\n",
    "\n",
    "            return next_level, next_trend, updated_szn\n",
    "\n",
    "        outputs, updates = theano.scan(hw_component_wise,\n",
    "               sequences = [\n",
    "                   ys[1:],\n",
    "#                    ys[szn_len:],\n",
    "                   is_covid_start[1:]\n",
    "#                    is_covid_start[szn_len:]\n",
    "        #            post_covid[szn_len:]\n",
    "               ],\n",
    "               outputs_info = [\n",
    "                   dict(initial = initial_level, taps=None),\n",
    "                   dict(initial = initial_trend, taps=None),\n",
    "                   dict(initial = initial_szns, taps=[-szn_len])\n",
    "               ], \n",
    "        #            non_sequences = \n",
    "               )\n",
    "\n",
    "\n",
    "        levels = outputs[0]\n",
    "        trends = outputs[1]\n",
    "        seasons = outputs[2]\n",
    "\n",
    "\n",
    "        levels_f = pm.math.concatenate([initial_level.reshape(1,1), levels[:-1]])\n",
    "        trends_f = pm.math.concatenate([initial_trend.reshape(1,1), trends[:-1]])\n",
    "        trends_f = trends_f * dampener ### pm.math.prod here?\n",
    "        seasons_f = pm.math.concatenate([initial_szns, seasons[:-szn_len]])\n",
    "\n",
    "        levels_and_trends = pm.math.stack([levels_f, trends_f])\n",
    "        level_plus_trend = levels_and_trends.sum(axis=0)\n",
    "\n",
    "        level_plus_trend_and_seasons = pm.math.stack([level_plus_trend, seasons_f])\n",
    "        y_hats = level_plus_trend_and_seasons.prod(axis=0)\n",
    "\n",
    "        sig = pm.HalfCauchy('sigma', beta=10)\n",
    "#         y_like = pm.Normal('y_like', mu=y_hats, sigma=sig, observed=zdf.iloc[szn_len-1:-1, :]['y_obs_lag-1'])\n",
    "        y_like = pm.Normal('y_like', mu=y_hats, sigma=sig, observed=zdf.iloc[:-1, :]['y_obs_lag-1'])\n",
    "        \n",
    "    map_estimate = pm.find_MAP(model=hw_model)\n",
    "    \n",
    "    return map_estimate, ys, is_covid_start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
